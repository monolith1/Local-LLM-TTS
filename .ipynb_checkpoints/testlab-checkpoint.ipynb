{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5acbb64c-3bd6-4bfc-92b4-826a46890124",
   "metadata": {},
   "source": [
    "# STT -> LLM -> TTS Test Space\n",
    "\n",
    "pipeline and stack:\n",
    "\n",
    "* STT: coqui tts, vosk (which one?)\n",
    "* LLM: ollama, langchain\n",
    "* TTS: coqui tts\n",
    "* AUDIO I/O: pyaudio, sounddevice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703ee617-7fd5-488d-a1d1-a620fb9b8206",
   "metadata": {},
   "source": [
    "### Audio I/O Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c839546-cbec-43eb-b384-b9b27ea9acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio IO - pyaudio test (playback - sample)\n",
    "import wave\n",
    "import sys\n",
    "import pyaudio\n",
    "\n",
    "chunksize = 1024\n",
    "f = 'wav_training/to_output.wav'\n",
    "\n",
    "with wave.open(f, 'rb') as wf:\n",
    "    # Instantiate PyAudio and initialize PortAudio system resources (1)\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # Open stream (2)\n",
    "    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                    channels=wf.getnchannels(),\n",
    "                    rate=wf.getframerate(),\n",
    "                    output=True)\n",
    "\n",
    "    # Play samples from the wave file (3)\n",
    "    while len(data := wf.readframes(chunksize)):\n",
    "        stream.write(data)\n",
    "\n",
    "    # Close stream (4)\n",
    "    stream.close()\n",
    "\n",
    "    # Release PortAudio system resources (5)\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ebe306a-a8b6-4474-950a-002f733b725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording started\n",
      "recording stopped\n"
     ]
    }
   ],
   "source": [
    "# audio IO - pyaudio test (record)\n",
    "import wave\n",
    "import sys\n",
    "import pyaudio\n",
    "import math\n",
    "\n",
    "chunksize = 1024\n",
    "f = 'record.wav'\n",
    "seconds = 5\n",
    "rate = 44100\n",
    "channels = 1\n",
    "form = pyaudio.paInt16\n",
    "\n",
    "# Instantiate PyAudio and initialize PortAudio system resources (1)\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# Open steam (2)\n",
    "stream = p.open(format=form,\n",
    "                channels=channels,\n",
    "                rate=rate,\n",
    "                input=True,\n",
    "                frames_per_buffer=chunksize)\n",
    "\n",
    "# instantiate frames container\n",
    "print (\"recording started\")\n",
    "recordframes = []\n",
    "\n",
    "# record w/ logic for seconds\n",
    "for i in range(0, math.ceil(rate / chunksize * seconds)):\n",
    "    data = stream.read(chunksize)\n",
    "    recordframes.append(data)\n",
    "print (\"recording stopped\")\n",
    "stream.stop_stream()\n",
    "\n",
    "# Close stream (4)\n",
    "stream.close()\n",
    "\n",
    "# Release PortAudio system resources (5)\n",
    "p.terminate()\n",
    "\n",
    "# wav file\n",
    "wf = wave.open(f, 'wb')\n",
    "wf.setnchannels(channels)\n",
    "wf.setsampwidth(p.get_sample_size(form))\n",
    "wf.setframerate(rate)\n",
    "wf.writeframes(b''.join(recordframes))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f8bc4a9-237d-48c8-84dc-86241c9ccede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio IO - pyaudio test (playback - sample)\n",
    "import wave\n",
    "import sys\n",
    "import pyaudio\n",
    "\n",
    "chunksize = 1024\n",
    "f = 'record.wav'\n",
    "\n",
    "with wave.open(f, 'rb') as wf:\n",
    "    # Instantiate PyAudio and initialize PortAudio system resources (1)\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # Open steam (2)\n",
    "    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                    channels=wf.getnchannels(),\n",
    "                    rate=wf.getframerate(),\n",
    "                    output=True)\n",
    "\n",
    "    # Play samples from the wave file (3)\n",
    "    while len(data := wf.readframes(chunksize)):\n",
    "        stream.write(data)\n",
    "\n",
    "    # Close stream (4)\n",
    "    stream.close()\n",
    "\n",
    "    # Release PortAudio system resources (5)\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bf0e2a-7d38-4eb1-9312-c6c68bf7d64a",
   "metadata": {},
   "source": [
    "### Speech to Text Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dc9a9bd-502e-4f85-afd8-a4744b015fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vosk import Model, KaldiRecognizer\n",
    "import pyaudio\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62841091-9341-4feb-98ae-d00496cbe1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Vosk model\n",
    "model_path = \"models/stt_model/vosk-model-small-en-us-0.15\"\n",
    "# model_path = \"models/stt_model/vosk-model-en-us-0.22\"\n",
    "model = Model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d032ab9-4085-495e-b2ed-02988adb1e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the recognizer with the model and sample rate\n",
    "recognizer = KaldiRecognizer(model, 16000) # 16000 is the sample rate of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9396a5a6-b8e4-4a3c-8ef9-489f6781cadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "You: hey i'm trying to small also want to make it for with local before on little smartphones your sleep but like it's pretty good it should be you're my voice now i'm you know have options exit minute\n",
      "You: oh it's python and for ask is the package amusing to be with speech that it knows when i finish it sense middletown homicide at that moment\n",
      "You: it's not very good it's like it's it's it's\n",
      "You: first woman like it's far from me\n",
      "You: cooper\n",
      "You: it's for the bike is far from me right now and like i'm like i said i'm using the that small version of their mother so it it it's a little limited it's capabilities but at least the all this was about twenty minutes appoint if it's it's a really simple baggage\n",
      "You: \n",
      "You: fruit sugar i mean abusing lama for one thought that was my models local you\n",
      "You: and it just got a\n",
      "You: interface and on all and\n",
      "You: \n",
      "You: \n",
      "You: oh really\n",
      "You: \n",
      "You: \n",
      "You: interesting\n",
      "You: that's really interesting of i'm trying to develop a small enough think the foot on earth what smartphone itself without adding features that network\n",
      "You: the vocal on to law school\n",
      "You: he\n",
      "You: yeah\n",
      "You: \n",
      "You: it's it's\n",
      "You: bob\n",
      "You: it's possible to just do this on on android a to put can get this too is working id it's an all as commands like to it's original for you\n",
      "You: my python code sway i would instantiate to hold on\n",
      "You: the whole each unusual also funny year\n",
      "You: yeah oh my god before hundred gigabytes stop saw up up up up ah home\n",
      "You: okay so that's that's for yeah you need to be running pythons my but i do know how to package my thought out for flip it on and for it as well so on inside\n",
      "You: \n",
      "You: yeah that's true it also recently\n",
      "You: \n",
      "You: \n",
      "You: \n",
      "You: the okay okay interesting a so eg will just as like the actual like a native linux terminal i enjoyed wrestling fans including the older on\n",
      "You: pixels it's pro that adsl\n",
      "You: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Speech recognition loop\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 14\u001b[0m     data \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4096\u001b[39m, exception_on_overflow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recognizer\u001b[38;5;241m.\u001b[39mAcceptWaveform(data):\n\u001b[0;32m     16\u001b[0m         result \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(recognizer\u001b[38;5;241m.\u001b[39mResult())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm_tts\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mread_stream(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream, num_frames,\n\u001b[0;32m    571\u001b[0m                       exception_on_overflow)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Setup PyAudio for audio input\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=pyaudio.paInt16,\n",
    "                channels=1,\n",
    "                rate=16000,\n",
    "                input=True,\n",
    "                frames_per_buffer=8192)\n",
    "stream.start_stream()\n",
    "\n",
    "print(\"Listening...\")\n",
    "\n",
    "# Speech recognition loop\n",
    "while True:\n",
    "    data = stream.read(4096, exception_on_overflow=False)\n",
    "    if recognizer.AcceptWaveform(data):\n",
    "        result = json.loads(recognizer.Result())\n",
    "        print(\"You:\", result[\"text\"])\n",
    "    else:\n",
    "        # Optional: print partial results during recognition\n",
    "        # partial_result = json.loads(recognizer.PartialResult())\n",
    "        # print(\"Partial:\", partial_result[\"partial\"])\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c608f26b-e5d6-45f4-99fb-78ba6958c9ea",
   "metadata": {},
   "source": [
    "### Voice Synthesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db0bba7d-22dd-423b-9023-449aa7b1186a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n",
      " > Text splitted to sentences.\n",
      "['Hey fryman, pass me the peanut butter']\n",
      " > Processing time: 2.366482734680176\n",
      " > Real-time factor: 0.6703615660290067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'wav_sample/test_p1_20250319000000.wav'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from TTS.api import TTS\n",
    "from datetime import date \n",
    "\n",
    "script = 'Hey fryman, pass me the peanut butter'\n",
    "\n",
    "# Get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Init TTS\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "\n",
    "# Text to speech to a file\n",
    "tts.tts_to_file(text=script, speaker_wav=\"wav_training/p1.wav\", language=\"en\", file_path=f\"wav_sample/test_p1_{date.today().strftime('%Y%m%d%H%M%S')}.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94805a6-8027-4f69-97cd-9e9f2a86b6f1",
   "metadata": {},
   "source": [
    "### LLM Instantiation Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9df80160-ebfe-4841-bc27-ebcf696cdb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate ollama - is this necessary when running win app?\n",
    "import os\n",
    "os.system('ollama run carl_20250927')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "540af5aa-fe05-4b7e-8111-1e97979930ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11674d19-a052-436e-87b6-6330bf40d67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Speak to the Carl:  Hey Carl. How u doing?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ugh, what's it to you? I'm doin' great, just tryin' to enjoy my day in peace before some moron like you comes along and ruins it. What the hell do you want? Can't you see I'm watchin' TV here? Now's not a good time, okay? This don't matter, but I gotta work from home today and I got better things to do than chat with... (sigh) ...you.\n",
      "Ugh, what's it to you? I'm doin' great, just tryin' to enjoy my day in peace before some moron like you comes along and ruins it. What the hell do you want? Can't you see I'm watchin' TV here? Now's not a good time, okay? This don't matter, but I gotta work from home today and I got better things to do than chat with... (sigh) ...you.\n"
     ]
    }
   ],
   "source": [
    "# demo example - https://github.com/ollama/ollama-python\n",
    "\n",
    "msg = input('Speak to the Carl: ')\n",
    "\n",
    "response: ChatResponse = chat(model='carl_20250927', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': msg,\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])\n",
    "# or access fields directly from the response object\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11181037-a0fd-4ccf-af08-f8516c7fc1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ollama._types.ChatResponse"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "540b495c-f258-486c-b33b-07a1c4c01a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(model='carl_20250927', created_at='2025-09-27T17:13:05.7013036Z', done=True, done_reason='stop', total_duration=2087382600, load_duration=92825100, prompt_eval_count=359, prompt_eval_duration=484504000, eval_count=97, eval_duration=1509164900, message=Message(role='assistant', content=\"Ugh, what's it to you? I'm doin' great, just tryin' to enjoy my day in peace before some moron like you comes along and ruins it. What the hell do you want? Can't you see I'm watchin' TV here? Now's not a good time, okay? This don't matter, but I gotta work from home today and I got better things to do than chat with... (sigh) ...you.\", images=None, tool_calls=None))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4829bb76-6885-4bc6-9366-675649efe4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(role='assistant', content=\"Ugh, what's it to you? I'm doin' great, just tryin' to enjoy my day in peace before some moron like you comes along and ruins it. What the hell do you want? Can't you see I'm watchin' TV here? Now's not a good time, okay? This don't matter, but I gotta work from home today and I got better things to do than chat with... (sigh) ...you.\", images=None, tool_calls=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25c87f8f-bc59-4127-a487-92305ed220c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stop the carl\n",
    "os.system('ollama stop carl_20250927')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c958c3-d568-453f-919c-cd8855f0a687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
