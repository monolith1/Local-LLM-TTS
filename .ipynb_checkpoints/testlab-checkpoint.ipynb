{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5acbb64c-3bd6-4bfc-92b4-826a46890124",
   "metadata": {},
   "source": [
    "# STT -> LLM -> TTS Test Space\n",
    "\n",
    "pipeline and stack:\n",
    "\n",
    "* STT: coqui tts, vosk (which one?)\n",
    "* LLM: ollama, langchain\n",
    "* TTS: coqui tts\n",
    "* AUDIO I/O: pyaudio, sounddevice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703ee617-7fd5-488d-a1d1-a620fb9b8206",
   "metadata": {},
   "source": [
    "### Audio I/O Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c839546-cbec-43eb-b384-b9b27ea9acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio IO - pyaudio test (playback - sample)\n",
    "import wave\n",
    "import sys\n",
    "import pyaudio\n",
    "\n",
    "chunksize = 1024\n",
    "f = 'output.wav'\n",
    "\n",
    "with wave.open(f, 'rb') as wf:\n",
    "    # Instantiate PyAudio and initialize PortAudio system resources (1)\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # Open steam (2)\n",
    "    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                    channels=wf.getnchannels(),\n",
    "                    rate=wf.getframerate(),\n",
    "                    output=True)\n",
    "\n",
    "    # Play samples from the wave file (3)\n",
    "    while len(data := wf.readframes(chunksize)):\n",
    "        stream.write(data)\n",
    "\n",
    "    # Close stream (4)\n",
    "    stream.close()\n",
    "\n",
    "    # Release PortAudio system resources (5)\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ebe306a-a8b6-4474-950a-002f733b725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording started\n",
      "recording stopped\n"
     ]
    }
   ],
   "source": [
    "# audio IO - pyaudio test (record)\n",
    "import wave\n",
    "import sys\n",
    "import pyaudio\n",
    "import math\n",
    "\n",
    "chunksize = 1024\n",
    "f = 'record.wav'\n",
    "seconds = 5\n",
    "rate = 44100\n",
    "channels = 1\n",
    "form = pyaudio.paInt16\n",
    "\n",
    "# Instantiate PyAudio and initialize PortAudio system resources (1)\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# Open steam (2)\n",
    "stream = p.open(format=form,\n",
    "                channels=channels,\n",
    "                rate=rate,\n",
    "                input=True,\n",
    "                frames_per_buffer=chunksize)\n",
    "\n",
    "# instantiate frames container\n",
    "print (\"recording started\")\n",
    "recordframes = []\n",
    "\n",
    "# record w/ logic for seconds\n",
    "for i in range(0, math.ceil(rate / chunksize * seconds)):\n",
    "    data = stream.read(chunksize)\n",
    "    recordframes.append(data)\n",
    "print (\"recording stopped\")\n",
    "stream.stop_stream()\n",
    "\n",
    "# Close stream (4)\n",
    "stream.close()\n",
    "\n",
    "# Release PortAudio system resources (5)\n",
    "p.terminate()\n",
    "\n",
    "# wave file\n",
    "wf = wave.open(f, 'wb')\n",
    "wf.setnchannels(channels)\n",
    "wf.setsampwidth(p.get_sample_size(form))\n",
    "wf.setframerate(rate)\n",
    "wf.writeframes(b''.join(recordframes))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f8bc4a9-237d-48c8-84dc-86241c9ccede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio IO - pyaudio test (playback - sample)\n",
    "import wave\n",
    "import sys\n",
    "import pyaudio\n",
    "\n",
    "chunksize = 1024\n",
    "f = 'record.wav'\n",
    "\n",
    "with wave.open(f, 'rb') as wf:\n",
    "    # Instantiate PyAudio and initialize PortAudio system resources (1)\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # Open steam (2)\n",
    "    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                    channels=wf.getnchannels(),\n",
    "                    rate=wf.getframerate(),\n",
    "                    output=True)\n",
    "\n",
    "    # Play samples from the wave file (3)\n",
    "    while len(data := wf.readframes(chunksize)):\n",
    "        stream.write(data)\n",
    "\n",
    "    # Close stream (4)\n",
    "    stream.close()\n",
    "\n",
    "    # Release PortAudio system resources (5)\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c608f26b-e5d6-45f4-99fb-78ba6958c9ea",
   "metadata": {},
   "source": [
    "### Voice Synthesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db0bba7d-22dd-423b-9023-449aa7b1186a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['Hey fryman, pass me the peanut butter']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "C:\\Users\\monol\\anaconda3\\envs\\llm_tts\\Lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:53: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 3.8737754821777344\n",
      " > Real-time factor: 1.1623224115776596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'wav_sample/test_p1_20250319000000.wav'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from TTS.api import TTS\n",
    "from datetime import date \n",
    "\n",
    "script = 'Hey fryman, pass me the peanut butter'\n",
    "\n",
    "# Get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Init TTS\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "\n",
    "# Text to speech to a file\n",
    "tts.tts_to_file(text=script, speaker_wav=\"wav_training/p1.wav\", language=\"en\", file_path=f\"wav_sample/test_p1_{date.today().strftime('%Y%m%d%H%M%S')}.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
